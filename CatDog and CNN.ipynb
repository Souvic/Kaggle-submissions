{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "batch_size=1024*4\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(16, (2, 2), batch_input_shape=(None,32, 32,3),padding='same',use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3),padding='same',use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3),padding='same',use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3),padding='same',use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Conv2D(16, (3, 3), activation='relu',padding='same'))\n",
    "#model.add(Conv2D(16, (3, 3), activation='relu',padding='same',use_bias=True))\n",
    "#model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(Conv2D(32, (3, 3), activation='relu',padding='same'))\n",
    "#model.add(Conv2D(16, (3, 3), activation='relu',padding='same',use_bias=True))\n",
    "#model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from keras.utils import plot_model\n",
    "#plot_model(model, to_file='model.png')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get data\n",
    "t=os.listdir(\"/Users/souvicchakraborty/Downloads/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t=np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dickon={\"cat\":0,\"dog\":1}\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gen_batch\n",
    "for i in range(5000):\n",
    "    indices=np.random.choice(len(t),batch_size,replace=True)\n",
    "    x=np.array([cv2.imread(\"/Users/souvicchakraborty/Downloads/train/\"+b,0) for b in t[indices]])\n",
    "\n",
    "    [cv2.copyMakeBorder(xx,0,0,0,(xx.shape[0]-xx.shape[1]), 0) for xx in x if xx.shape[0] > xx.shape[1]]\n",
    "\n",
    "    [cv2.copyMakeBorder(xx,0,(xx.shape[1]-xx.shape[0]),0,0, 0) for xx in x if ((xx.shape[1]>xx.shape[0] ))]\n",
    "\n",
    "    x=[cv2.resize(xx,(128,128), interpolation =  cv2.INTER_LINEAR).reshape((32,32,1)).tolist() for xx in x]\n",
    "    x_batch=(np.array(x)-117.0)/255.0\n",
    "    y_batch=np.array([dickon[b.split(\".\")[0]] for b in t[indices]])\n",
    "    if(i%10==1):\n",
    "        print(i//10,model.test_on_batch(x_batch, y_batch))\n",
    "\n",
    "    model.train_on_batch(x_batch, y_batch)\n",
    "    #model.train_on_batch(x_batch, y_batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gen_batch\n",
    "tqp=time.time()\n",
    "for i in range(10000):\n",
    "    indices=np.random.choice(len(t),batch_size,replace=True)\n",
    "    x=np.array([cv2.imread(\"/Users/souvicchakraborty/Downloads/train/\"+b,0) for b in t[indices]])\n",
    "\n",
    "    [cv2.copyMakeBorder(xx,0,0,0,(xx.shape[0]-xx.shape[1]), 0) for xx in x if xx.shape[0] > xx.shape[1]]\n",
    "\n",
    "    [cv2.copyMakeBorder(xx,0,(xx.shape[1]-xx.shape[0]),0,0, 0) for xx in x if ((xx.shape[1]>xx.shape[0] ))]\n",
    "\n",
    "    x=[cv2.resize(xx,(128,128), interpolation =  cv2.INTER_LINEAR).reshape((128,128,1)).tolist() for xx in x]\n",
    "    \n",
    "    x_batch=(np.array(x)-115.5)/66\n",
    "    del(x)\n",
    "    y_batch=np.array([dickon[b.split(\".\")[0]] for b in t[indices]])\n",
    "    if(i%10==0):\n",
    "        print(time.time()-tqp)\n",
    "        print(i/100,model.test_on_batch(x_batch, y_batch))\n",
    "\n",
    "    model.train_on_batch(x_batch, y_batch)\n",
    "    #model.train_on_batch(x_batch, y_batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(x_batch.shape)\n",
    "x_batch=np.array([[0]*3])\n",
    "y_batch=np.array([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for tt in range(100):\n",
    " #   t=np.roll(t,batch_size)\n",
    "  #  x=np.array([[np.mean(cv2.imread(\"/Users/souvicchakraborty/Downloads/train/\"+b)[cx]) for cx in range(3)] for b in t[:batch_size]])\n",
    "   # print(x.shape)\n",
    "    ##x=[ for xx in x]\n",
    "   # x_batch=np.append(x_batch,np.array(x),axis=0)\n",
    "    #y_batch=np.append(y_batch,np.array([dickon[b.split(\".\")[0]] for b in t[:batch_size]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t[:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.append(np.array([1,2]),np.array([1,2]))"
   ]
  },
  {
   
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(x_batch,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_batch[:78].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(np.multiply((1-y_batch[1:780]).reshape((779,1)),x_batch[1:780]),axis=0)/np.sum(1-y_batch[1:780])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(np.multiply((y_batch[1:780]).reshape((779,1)),x_batch[1:780]),axis=0)/np.sum(y_batch[1:780])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.imwrite(\"/Users/souvicchakraborty/Downloads/aqw.jpeg\",cv2.resize(cv2.imread(\"/Users/souvicchakraborty/Downloads/train/dog.7954.jpg\",0),(32,32), interpolation =  cv2.INTER_LINEAR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tte=os.listdir(\"/Users/souvicchakraborty/Downloads/test1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(tte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputt=[]\n",
    "for i in range(195):\n",
    "    x=np.array([cv2.imread(\"/Users/souvicchakraborty/Downloads/test1/\"+hgh,0) for hgh in tte[(i*64):(64*(i+1)) ]])\n",
    "\n",
    "    [cv2.copyMakeBorder(xx,0,0,0,(xx.shape[0]-xx.shape[1]), 0) for xx in x if xx.shape[0] > xx.shape[1]]\n",
    "\n",
    "    [cv2.copyMakeBorder(xx,0,(xx.shape[1]-xx.shape[0]),0,0, 0) for xx in x if ((xx.shape[1]>xx.shape[0] ))]\n",
    "\n",
    "    x=[cv2.resize(xx,(128,128), interpolation =  cv2.INTER_LINEAR).reshape((128,128,1)).tolist() for xx in x]\n",
    "    \n",
    "    x_batch=(np.array(x)-115.5)/66\n",
    "    outputt=np.append(outputt,(model.predict(x_batch,batch_size=64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "12500%64\n",
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.array([cv2.imread(\"/Users/souvicchakraborty/Downloads/test1/\"+hgh,0) for hgh in tte[(len(tte)-64):]])\n",
    "\n",
    "[cv2.copyMakeBorder(xx,0,0,0,(xx.shape[0]-xx.shape[1]), 0) for xx in x if xx.shape[0] > xx.shape[1]]\n",
    "\n",
    "[cv2.copyMakeBorder(xx,0,(xx.shape[1]-xx.shape[0]),0,0, 0) for xx in x if ((xx.shape[1]>xx.shape[0] ))]\n",
    "\n",
    "x=[cv2.resize(xx,(128,128), interpolation =  cv2.INTER_LINEAR).reshape((128,128,1)).tolist() for xx in x]\n",
    "    \n",
    "x_batch=(np.array(x)-115.5)/66\n",
    "outputtt=(model.predict(x_batch,batch_size=64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(outputt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outy=np.append(outputt,outputtt[44:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(outy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outy=1*(outy<0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels=[d[:(len(d)-4)] for d in tte]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqw=pd.read_csv(\"/Users/souvicchakraborty/Downloads/sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqw['label']=iu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iu=[outy[np.argmax(1*(np.array(labels).astype('int'))==l)] for l in np.array(sqw[['id']]).flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.array(sqw[['id']]).flatten()==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqw.to_csv(\"/Users/souvicchakraborty/Downloads/kindafinal.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqw['label']#=[(((1-ttw)-0.5)*0.8)+0.5 for ttw in iu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (2, 2), batch_input_shape=(None,128, 128,1),padding='same',use_bias=True))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3),padding='same',use_bias=True))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, (3, 3),padding='same',use_bias=True))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3),padding='same',use_bias=True))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Conv2D(16, (3, 3),padding='same',use_bias=True))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3),padding='same',use_bias=True))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3),padding='same',use_bias=True))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3),padding='same',use_bias=True))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dense(64))\n",
    "\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128,use_bias=True))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dense(1,use_bias=True))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
