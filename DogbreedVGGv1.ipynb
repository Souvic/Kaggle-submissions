{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import ssl\n",
    "\n",
    "#try:\n",
    " #   _create_unverified_https_context = ssl._create_unverified_context\n",
    "#except AttributeError:\n",
    "    # Legacy Python that doesn't verify HTTPS certificates by default\n",
    " #   pass\n",
    "#else:\n",
    "    # Handle target environment that doesn't support HTTPS verification\n",
    " #   ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vgg16_conv = VGG16(weights='imagenet', include_top=False)\n",
    "model_vgg16_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pre-processing\n",
    "#get data\n",
    "trainLocation=\"./DogBreed/train/\"\n",
    "t=os.listdir(trainLocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datatrain=[trainLocation+j for j in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatrainImages=[cv2.imread(j,1) for j in datatrain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m=[a.shape for a in datatrainImages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resizedimages=[cv2.resize(img,None,fx=224/max(img.shape),fy= 224/max(img.shape), interpolation = cv2.INTER_AREA) for img in  datatrainImages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(datatrainImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "moddatatrainImages=[np.pad(a, [(0, 224-a.shape[0]), (0, 224-a.shape[1]), (0,0)], mode='constant') for a in resizedimages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(moddatatrainImages[1][:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(moddatatrainImages[1],axis=(1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moddatatrainImages=np.array(moddatatrainImages).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "moddatatrainImages[:,:,0] -= 103.939\n",
    "moddatatrainImages[:,:,1] -= 116.779\n",
    "moddatatrainImages[:,:,2] -= 123.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(resizedimagesimages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moddatatrainImages1 = moddatatrainImages.transpose((2,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#histmodtrainimages=[cv2.equalizeHist(img) for img in moddatatrainImages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=cv2.cvtColor(moddatatrainImages[1],cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gg=np.outer(moddatatrainImages[1],cv2.equalizeHist(aa).astype(float)/(aa.astype(float)+0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq=model_vgg16_conv.predict(np.array(moddatatrainImages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10222, 7, 7, 512)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('vggfeatures2', pq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#del(pq)\n",
    "del(moddatatrainImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#del(ftrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelstrain=pd.read_csv('./DogBreed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "plk=[dd+'.jpg' for dd in labelstrain['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices=[np.argwhere(plk==lkl) for lkl in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices[1:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plk[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plk[0]==t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelstrain=labelstrain['breed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlabs=set(labelstrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diclabs={a[1]:a[0] for a in enumerate(dlabs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_x=np.load('vggfeatures2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_x=[sdf.flatten() for sdf in x_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_x=np.array(x_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ohcc=np.eye(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_y=np.array([ohcc[diclabs[j]] for j in labelstrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_x[:7000]; y_train=y_y[:7000];x_test=x_x[7000:];y_test=y_y[7000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 120)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Dropout\n",
    "model.add(Dropout(0.5, input_shape=(512*7*7,)))\n",
    "model.add(Dense(units=512*2))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(units=512))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(units=120))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.SGD(lr=0.02),#'sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.6018 - acc: 0.7471    \n",
      "Epoch 2/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.5840 - acc: 0.7517    \n",
      "Epoch 3/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.5766 - acc: 0.7464    \n",
      "Epoch 4/200\n",
      "7000/7000 [==============================] - 13s - loss: 1.5558 - acc: 0.7567    \n",
      "Epoch 5/200\n",
      "7000/7000 [==============================] - 13s - loss: 1.5416 - acc: 0.7611    \n",
      "Epoch 6/200\n",
      "7000/7000 [==============================] - 13s - loss: 1.5260 - acc: 0.7633    \n",
      "Epoch 7/200\n",
      "7000/7000 [==============================] - 13s - loss: 1.5124 - acc: 0.7649    \n",
      "Epoch 8/200\n",
      "7000/7000 [==============================] - 13s - loss: 1.4975 - acc: 0.7654    \n",
      "Epoch 9/200\n",
      "7000/7000 [==============================] - 13s - loss: 1.4824 - acc: 0.7666    \n",
      "Epoch 10/200\n",
      "7000/7000 [==============================] - 13s - loss: 1.4677 - acc: 0.7723    \n",
      "Epoch 11/200\n",
      "7000/7000 [==============================] - 13s - loss: 1.4576 - acc: 0.7724    \n",
      "Epoch 12/200\n",
      "7000/7000 [==============================] - 13s - loss: 1.4366 - acc: 0.7743    \n",
      "Epoch 13/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.4227 - acc: 0.7883    \n",
      "Epoch 14/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.4135 - acc: 0.7841    \n",
      "Epoch 15/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.3971 - acc: 0.7854    \n",
      "Epoch 16/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.3833 - acc: 0.7896    \n",
      "Epoch 17/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.3723 - acc: 0.7899    \n",
      "Epoch 18/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.3574 - acc: 0.7940    \n",
      "Epoch 19/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.3482 - acc: 0.7957    \n",
      "Epoch 20/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.3376 - acc: 0.7971    \n",
      "Epoch 21/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.3244 - acc: 0.7946    \n",
      "Epoch 22/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.3124 - acc: 0.7989    \n",
      "Epoch 23/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.3086 - acc: 0.8007    \n",
      "Epoch 24/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.2893 - acc: 0.8064    \n",
      "Epoch 25/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.2736 - acc: 0.8046    \n",
      "Epoch 26/200\n",
      "7000/7000 [==============================] - 13s - loss: 1.2663 - acc: 0.8059    \n",
      "Epoch 27/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.2553 - acc: 0.8093    \n",
      "Epoch 28/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.2478 - acc: 0.8094    \n",
      "Epoch 29/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.2333 - acc: 0.8167    \n",
      "Epoch 30/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.2218 - acc: 0.8191    \n",
      "Epoch 31/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.2099 - acc: 0.8173    \n",
      "Epoch 32/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.1969 - acc: 0.8220    \n",
      "Epoch 33/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.1834 - acc: 0.8217    \n",
      "Epoch 34/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.1830 - acc: 0.8233    \n",
      "Epoch 35/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.1675 - acc: 0.8237    \n",
      "Epoch 36/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.1554 - acc: 0.8263    \n",
      "Epoch 37/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.1531 - acc: 0.8249    \n",
      "Epoch 38/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.1396 - acc: 0.8326    \n",
      "Epoch 39/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.1290 - acc: 0.8289    \n",
      "Epoch 40/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.1199 - acc: 0.8359    \n",
      "Epoch 41/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.1093 - acc: 0.8363    \n",
      "Epoch 42/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.0939 - acc: 0.8417    \n",
      "Epoch 43/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.0884 - acc: 0.8434    \n",
      "Epoch 44/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.0781 - acc: 0.8440    \n",
      "Epoch 45/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.0718 - acc: 0.8453    \n",
      "Epoch 46/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.0616 - acc: 0.8461    \n",
      "Epoch 47/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.0499 - acc: 0.8514    \n",
      "Epoch 48/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.0459 - acc: 0.8500    \n",
      "Epoch 49/200\n",
      "7000/7000 [==============================] - 13s - loss: 1.0328 - acc: 0.8467    \n",
      "Epoch 50/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.0274 - acc: 0.8490    \n",
      "Epoch 51/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.0163 - acc: 0.8557    \n",
      "Epoch 52/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.0105 - acc: 0.8560    \n",
      "Epoch 53/200\n",
      "7000/7000 [==============================] - 12s - loss: 1.0005 - acc: 0.8596    \n",
      "Epoch 54/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.9919 - acc: 0.8649    \n",
      "Epoch 55/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.9834 - acc: 0.8626    \n",
      "Epoch 56/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.9748 - acc: 0.8629    \n",
      "Epoch 57/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.9726 - acc: 0.8604    \n",
      "Epoch 58/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.9573 - acc: 0.8650    \n",
      "Epoch 59/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.9510 - acc: 0.8681    \n",
      "Epoch 60/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.9428 - acc: 0.8656    \n",
      "Epoch 61/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.9341 - acc: 0.8643    \n",
      "Epoch 62/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.9307 - acc: 0.8699    \n",
      "Epoch 63/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.9223 - acc: 0.8739    \n",
      "Epoch 64/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.9151 - acc: 0.8737    \n",
      "Epoch 65/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.9032 - acc: 0.8776    \n",
      "Epoch 66/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.9020 - acc: 0.8763    \n",
      "Epoch 67/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.8927 - acc: 0.8764    \n",
      "Epoch 68/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.8851 - acc: 0.8791    \n",
      "Epoch 69/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.8764 - acc: 0.8793    \n",
      "Epoch 70/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.8650 - acc: 0.8851    \n",
      "Epoch 71/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.8618 - acc: 0.8841    \n",
      "Epoch 72/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.8514 - acc: 0.8859    \n",
      "Epoch 73/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.8460 - acc: 0.8881    \n",
      "Epoch 74/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.8415 - acc: 0.8839    \n",
      "Epoch 75/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.8280 - acc: 0.8907    \n",
      "Epoch 76/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.8276 - acc: 0.8927    \n",
      "Epoch 77/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.8192 - acc: 0.8919    \n",
      "Epoch 78/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.8170 - acc: 0.8929    \n",
      "Epoch 79/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.8024 - acc: 0.8937    \n",
      "Epoch 80/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.7929 - acc: 0.8981    \n",
      "Epoch 81/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.7965 - acc: 0.8956    \n",
      "Epoch 82/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.7879 - acc: 0.8964    \n",
      "Epoch 83/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.7813 - acc: 0.8986    \n",
      "Epoch 84/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.7751 - acc: 0.9054    \n",
      "Epoch 85/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.7664 - acc: 0.9027    \n",
      "Epoch 86/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.7612 - acc: 0.9019    \n",
      "Epoch 87/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 12s - loss: 0.7559 - acc: 0.9046    \n",
      "Epoch 88/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.7460 - acc: 0.9100    \n",
      "Epoch 89/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.7435 - acc: 0.9104    \n",
      "Epoch 90/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.7448 - acc: 0.9053    \n",
      "Epoch 91/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.7350 - acc: 0.9090    \n",
      "Epoch 92/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.7267 - acc: 0.9124    \n",
      "Epoch 93/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.7161 - acc: 0.9119    \n",
      "Epoch 94/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.7177 - acc: 0.9096    \n",
      "Epoch 95/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.7159 - acc: 0.9144    \n",
      "Epoch 96/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.7057 - acc: 0.9107    \n",
      "Epoch 97/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.6975 - acc: 0.9136    \n",
      "Epoch 98/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.6990 - acc: 0.9136    \n",
      "Epoch 99/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.6884 - acc: 0.9183    \n",
      "Epoch 100/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.6798 - acc: 0.9186    \n",
      "Epoch 101/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.6768 - acc: 0.9213    \n",
      "Epoch 102/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.6649 - acc: 0.9234    \n",
      "Epoch 103/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.6656 - acc: 0.9176    \n",
      "Epoch 104/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.6592 - acc: 0.9257    \n",
      "Epoch 105/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.6630 - acc: 0.9209    \n",
      "Epoch 106/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.6497 - acc: 0.9256    \n",
      "Epoch 107/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.6446 - acc: 0.9250    \n",
      "Epoch 108/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.6429 - acc: 0.9273    \n",
      "Epoch 109/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.6349 - acc: 0.9290    \n",
      "Epoch 110/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.6292 - acc: 0.9273    \n",
      "Epoch 111/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.6300 - acc: 0.9281    \n",
      "Epoch 112/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.6202 - acc: 0.9296    \n",
      "Epoch 113/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.6142 - acc: 0.9319    \n",
      "Epoch 114/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.6122 - acc: 0.9310    \n",
      "Epoch 115/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.6074 - acc: 0.9341    \n",
      "Epoch 116/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.6082 - acc: 0.9334    \n",
      "Epoch 117/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.5940 - acc: 0.9381    \n",
      "Epoch 118/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.5924 - acc: 0.9376    \n",
      "Epoch 119/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.5889 - acc: 0.9381    \n",
      "Epoch 120/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.5879 - acc: 0.9376    \n",
      "Epoch 121/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.5806 - acc: 0.9360    \n",
      "Epoch 122/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.5714 - acc: 0.9379    \n",
      "Epoch 123/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.5686 - acc: 0.9416    \n",
      "Epoch 124/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.5651 - acc: 0.9383    \n",
      "Epoch 125/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.5612 - acc: 0.9444    \n",
      "Epoch 126/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.5609 - acc: 0.9416    \n",
      "Epoch 127/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.5564 - acc: 0.9420    \n",
      "Epoch 128/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.5512 - acc: 0.9453    \n",
      "Epoch 129/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.5416 - acc: 0.9493    \n",
      "Epoch 130/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.5417 - acc: 0.9466    \n",
      "Epoch 131/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.5409 - acc: 0.9443    \n",
      "Epoch 132/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.5355 - acc: 0.9469    \n",
      "Epoch 133/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.5279 - acc: 0.9457    \n",
      "Epoch 134/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.5258 - acc: 0.9464    \n",
      "Epoch 135/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.5240 - acc: 0.9481    \n",
      "Epoch 136/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.5173 - acc: 0.9507    \n",
      "Epoch 137/200\n",
      "7000/7000 [==============================] - 14s - loss: 0.5169 - acc: 0.9496    \n",
      "Epoch 138/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.5143 - acc: 0.9510    \n",
      "Epoch 139/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.5097 - acc: 0.9526    \n",
      "Epoch 140/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.5007 - acc: 0.9534    \n",
      "Epoch 141/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.4952 - acc: 0.9526    \n",
      "Epoch 142/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.4991 - acc: 0.9519    \n",
      "Epoch 143/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.4923 - acc: 0.9564    \n",
      "Epoch 144/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.4886 - acc: 0.9541    \n",
      "Epoch 145/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.4881 - acc: 0.9566    \n",
      "Epoch 146/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.4799 - acc: 0.9566    \n",
      "Epoch 147/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.4762 - acc: 0.9620    \n",
      "Epoch 148/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.4714 - acc: 0.9600    \n",
      "Epoch 149/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.4702 - acc: 0.9579    \n",
      "Epoch 150/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.4642 - acc: 0.9616    \n",
      "Epoch 151/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.4656 - acc: 0.9607    \n",
      "Epoch 152/200\n",
      "7000/7000 [==============================] - 15s - loss: 0.4625 - acc: 0.9620    \n",
      "Epoch 153/200\n",
      "7000/7000 [==============================] - 14s - loss: 0.4535 - acc: 0.9620    \n",
      "Epoch 154/200\n",
      "7000/7000 [==============================] - 14s - loss: 0.4537 - acc: 0.9639    \n",
      "Epoch 155/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.4530 - acc: 0.9617    \n",
      "Epoch 156/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.4519 - acc: 0.9611    \n",
      "Epoch 157/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.4410 - acc: 0.9660    \n",
      "Epoch 158/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.4460 - acc: 0.9621    \n",
      "Epoch 159/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.4367 - acc: 0.9639    \n",
      "Epoch 160/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.4291 - acc: 0.9681    \n",
      "Epoch 161/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.4318 - acc: 0.9653    \n",
      "Epoch 162/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.4297 - acc: 0.9653    \n",
      "Epoch 163/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.4259 - acc: 0.9670    \n",
      "Epoch 164/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.4213 - acc: 0.9659    \n",
      "Epoch 165/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.4218 - acc: 0.9670    \n",
      "Epoch 166/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.4104 - acc: 0.9696    \n",
      "Epoch 167/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.4137 - acc: 0.9694    \n",
      "Epoch 168/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.4083 - acc: 0.9701    \n",
      "Epoch 169/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.4067 - acc: 0.9690    \n",
      "Epoch 170/200\n",
      "7000/7000 [==============================] - 15s - loss: 0.4030 - acc: 0.9710    \n",
      "Epoch 171/200\n",
      "7000/7000 [==============================] - 14s - loss: 0.4048 - acc: 0.9727    \n",
      "Epoch 172/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 15s - loss: 0.3967 - acc: 0.9726    \n",
      "Epoch 173/200\n",
      "7000/7000 [==============================] - 15s - loss: 0.3966 - acc: 0.9711    \n",
      "Epoch 174/200\n",
      "7000/7000 [==============================] - 14s - loss: 0.3951 - acc: 0.9723    \n",
      "Epoch 175/200\n",
      "7000/7000 [==============================] - 14s - loss: 0.3885 - acc: 0.9719    \n",
      "Epoch 176/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.3862 - acc: 0.9737    \n",
      "Epoch 177/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.3852 - acc: 0.9719    \n",
      "Epoch 178/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.3825 - acc: 0.9750    \n",
      "Epoch 179/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.3805 - acc: 0.9723    \n",
      "Epoch 180/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.3754 - acc: 0.9746    \n",
      "Epoch 181/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.3777 - acc: 0.9741    \n",
      "Epoch 182/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.3678 - acc: 0.9773    \n",
      "Epoch 183/200\n",
      "7000/7000 [==============================] - 14s - loss: 0.3680 - acc: 0.9757    \n",
      "Epoch 184/200\n",
      "7000/7000 [==============================] - 14s - loss: 0.3656 - acc: 0.9763    \n",
      "Epoch 185/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.3701 - acc: 0.9766    \n",
      "Epoch 186/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.3598 - acc: 0.9744    \n",
      "Epoch 187/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.3599 - acc: 0.9749    \n",
      "Epoch 188/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.3551 - acc: 0.9794    \n",
      "Epoch 189/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.3535 - acc: 0.9770    \n",
      "Epoch 190/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.3529 - acc: 0.9783    \n",
      "Epoch 191/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.3496 - acc: 0.9774    \n",
      "Epoch 192/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.3518 - acc: 0.9761    \n",
      "Epoch 193/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.3430 - acc: 0.9813    \n",
      "Epoch 194/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.3453 - acc: 0.9760    \n",
      "Epoch 195/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.3388 - acc: 0.9786    \n",
      "Epoch 196/200\n",
      "7000/7000 [==============================] - 13s - loss: 0.3365 - acc: 0.9826    \n",
      "Epoch 197/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.3377 - acc: 0.9784    \n",
      "Epoch 198/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.3320 - acc: 0.9796    \n",
      "Epoch 199/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.3313 - acc: 0.9813    \n",
      "Epoch 200/200\n",
      "7000/7000 [==============================] - 12s - loss: 0.3275 - acc: 0.9813    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11e1706a0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=200, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3222 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2902303588530946, 0.63190564859142817]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(x_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
